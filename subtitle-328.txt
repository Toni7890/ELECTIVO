[MÚSICA] Hola y bienvenidos a Python for Everybody. Estamos haciendo un código de muestra. Puedes hacerte con el código postal de muestra si quieres seguirlo. Así que retomamos el punto intermedio, donde ejecutamos una araña simple que recupera datos y los colocamos para ejecutar este archivo spider.py. Estamos dando vueltas y haciendo cosas, y lo bonito de todos estos procesos de araña es que puedo detenerlos en cualquier momento y pulsar Ctrl+C. Así que echamos un vistazo al archivo SQLite de la araña y lo recuperamos. Y parece que tenemos 302 páginas, no sé cuántas hemos recuperado. 70, está bien, ahí vamos. Tengo unos 100, espera, estoy buscando lo incorrecto. Nulo, nulo, nulo, nulo, nulo, sí, tenemos unas 107 páginas. Así que lo que vamos a hacer ahora con 107 páginas es ejecutar el algoritmo PageRank, ¿de acuerdo? Echemos un vistazo a ese código. Así que la idea del ranking de páginas es que vamos a utilizar este algoritmo de PageRank. El ajuste predeterminado solo restablece el ranking de la página y el sprank ejecuta tantas iteraciones del ranking de la página. Así que la idea básica es que si miraras los enlaces aquí. Pensamos que el hecho de que la página uno apunte a la página dos le da algo de amor a la página dos. La página cuatro tiene cierto valor que le da a la página uno. Continúa y la página 2 le da amor a la página 46 una y otra vez. Pero el problema es que ¿qué tan buena es la primera página y cuánto karma positivo le da a la segunda página? Entonces, lo que pasa es que empezamos por darle a cada página una clasificación de uno. Decimos que todo el mundo empieza igual. Pero luego lo que hacemos es dividirlo en una iteración del algoritmo PageRank. Dividimos los beneficios de una página entre sus enlaces salientes y luego los acumulamos. Y ese se convierte en el siguiente rango, ¿de acuerdo? Y entonces, echemos un vistazo al código del algoritmo PageRank. Así que esto es bastante simple. Solo importa SQLite 3 porque realmente hace todo lo que hay en la base de datos, ¿verdad? Actualizará estas columnas aquí mismo en la base de datos. Así que vamos a hacer algunas cosas aquí para acelerar esto. Si piensas en Google, este ranking es lento y va a funcionar continuamente para seguir actualizando estas cosas. Lo primero que hago es leer todos los from_ids de los enlaces, SELECT DISTINCT descarta los duplicados. Así que tengo todos los identificadores de origen , que son todas las páginas que tienen enlaces a otras páginas. Como todas las páginas están en páginas pero en enlaces para tener un identificador de origen, también debes tener un identificador de destino. De acuerdo, también vamos a ver las páginas que reciben el ranking de páginas. Y estamos almacenando estas cosas previamente en caché, ¿vale? Vamos a hacer un SELECT DISTINCT entre from_id y to_id y recorreremos ese grupo de cosas. Y aquí estamos haciendo una lista de enlaces. Y por eso decimos que si el from_id es el mismo que el to_id, no nos interesa. Si el from_id no está ya en mis from_ids que tengo, lo voy a omitir. Si el to_id no está en el from_id, significa que no queremos enlaces que apunten a ninguna parte. O apunta a páginas que aún no hemos recuperado. Eso es lo que quiere decir, así que es un filtro para los from_ids y los to_ids de la tabla de enlaces. De modo que solo sean los enlaces los que apunten a otra página que ya hayamos recuperado. Y luego haremos un seguimiento de todo el superconjunto de to_ids, los ID de destino. Y voy a ponerlos todos en listas para no tener que molestar tanto a la base de datos, ¿vale ? Así que esto es obtener lo que se llama el componente fuertemente conectado. Lo que significa que en cualquiera de estos ID hay una ruta desde cada ID a cada uno de los demás, eventualmente. En la teoría de grafos, a eso se le llama el componente fuertemente conectado. Entonces, lo que vamos a hacer es seleccionar new_rank de Pages para todos los from_ids, ¿verdad? Vamos a tener un diccionario que se base en el identificador, la clave principal, que es lo que es el nodo, igual al rango. Por lo tanto, si miramos nuestra base de datos, eso significa que para la parte del componente fuertemente conectado en los enlaces. Vamos a coger este número y ponerlo en un diccionario basándonos en la clave principal, este número de aquí. Vamos a tener un diccionario con esto asignado a eso. De nuevo, queremos hacerlo lo más rápido posible. Ahora, solo haremos una iteración al principio. Así que pregunta cuántas veces quieres ejecutarlo, ¿de acuerdo? Así que hacemos un número entero de eso. Comprobamos si hay algún valor ahí. Si no hay valores, somos malos. Y ahora vamos a decir que I es igual a 1 para el rango (muchos). Va a ser uno a uno, por lo que podría ejecutarse tantas veces como sea. Y luego, lo que va a hacer es calcular las nuevas clasificaciones de las páginas. Entonces, lo que realmente va a hacer es tomar el ranking de la página, los rangos anteriores, y recorrerlos, y el ranking anterior es el mapeo de la clave principal con el rango de la página anterior, ¿de acuerdo? Y para cada nodo tendremos total = total + old_rank. Y luego vamos a establecer el valor de next_ranks en 0, ¿de acuerdo? Y luego, lo que vamos a hacer es calcular el número de enlaces salientes para cada elemento de clasificación de página. Así que node y old_rank están en la lista de los rangos anteriores. Estos son los identificadores a los que se lo vamos a dar. Por lo tanto, para este nodo en particular, vamos a tener los enlaces salientes. Y vamos a revisar los enlaces y no a vincularnos consigo mismo. Aunque nos hemos asegurado de que eso no suceda. Nos aseguramos de ello, pero luego haremos una lista llamada give_ids con los identificadores con los que el nodo va a compartir sus ventajas. Y ahora lo que vamos a hacer es decir cuánta bondad vamos a hacer fluir hacia el exterior. Basado en nuestra clasificación anterior de este nodo en particular y en la cantidad de enlaces salientes que tenemos. Así que esa es la cantidad que vamos a dar en nuestros enlaces salientes. Y luego, lo que estamos haciendo son todos los identificadores a los que se los estamos dando, y empezamos con next_ranks siendo 0 para estas personas. Estos son los receptores y vamos a añadir la cantidad de ranking de página a cada uno de ellos. Sea lo que sea, revisaremos todos los enlaces y revelaremos partes fraccionarias de nuestra bondad actual. Y se acumula en cada uno de ellos, por lo que, eventualmente, a todos los enlaces entrantes se les otorgará un valor de enlace nuevo. Bien, ahora voy a repasar y calcular el nuevo total. Y esta evaporación, la idea es que tenga que ver con el algoritmo PageRank. Que hay formas disfuncionales en las que el PageRank puede quedar atrapado. Y esta evaporación le está quitando una fracción a todo el mundo y devolviéndola a todos los demás. Y entonces añadimos este factor evaporativo. Y luego vamos a hacer algunos cálculos para mostrar algunas cosas. Y es que estamos calculando la diferencia promedio entre las clasificaciones de las páginas. Y verás esto cuando empiece a ejecutarlo. Y eso nos dice que esto nos va a indicar la estabilidad del ranking de la página. Entonces, de una iteración a la siguiente, cuanto más cambia, menos estable es. Y verás en un segundo que estas cosas se estabilizan. Y decimos, ¿cuál es la diferencia promedio en las clasificaciones de las páginas por nodo? Que es lo que es esto. Y eso es lo que vamos a imprimir, y ahora vamos a tomar los new_ranks y convertirlos en los old_ranks, y luego volveremos a ejecutar loop. Así que en realidad no actualizo la base de datos cada vez que realizo la iteración del ranking de páginas. Pero al final, actualizaré todas estas cosas y actualizaré todas las clasificaciones con las nuevas. Así que voy a hacer un cálculo en memoria para que este bucle se ejecute a toda velocidad. Aunque quiera hacer este bucle 100 o 1000 veces, en realidad todo se basa en estructuras de datos de memoria. Bien, probablemente sea más fácil para mí mostrarles esto, el código se ejecuta de manera bastante simple. Python3 sprank.py. Así que solo voy a ejecutarlo durante una iteración y eso significa que su bucle aquí solo se ejecutará una vez. Así que vamos a empezar con las clasificaciones de las páginas. El nuevo rango es 1, y solo va a ejecutar 1 iteración y poner el rango ahí, ¿de acuerdo? Y luego actualiza esto también. Así que sigamos y ejecutémoslo una vez para una iteración. Bien, entonces ejecutó una iteración, y el cambio promedio entre el rango anterior y el nuevo rango es uno. Así que, en realidad, es una locura, así que voy a refrescarme aquí. Y verás que el rango anterior era uno. Y el nuevo rango está muy abajo, muy abajo, muy abajo, abajo un poco, abajo un poco, arriba un montón, abajo, abajo, arriba. Así que puedes ver que bajaban y subían. Ahora la suma de todos estos números va a ser la misma, ¿no?, porque lo único que hizo fue hacerlo flotar y volver a calcularlo. Y eso es lo que ocurre con el page rank. Entonces, lo que pasará es si ejecuto una iteración más del ranking de páginas. Estos números se usarán para calcular el nuevo rango y este se calculará para el rango anterior. Verás que volverán a cambiar, así que lo ejecutaré una vez más. Así que voy a ejecutar una iteración. Y luego voy a pulsar Actualizar. Así que, verás, todos estos números fueron copiados. Pero ahora hay un nuevo rango que se calcula en base a estos tipos. Y así que este subió. Este era de 0.13, ha subido un poco. Este ha subido un poco más. Este ha subido. Este se hundió, ¿de acuerdo? Así que este bajó de 6 a 8. Y pueden ver que la diferencia ahora es la diferencia promedio entre este número y este número entre todos ellos pasó de 1 punto a 0.41. Y verás que con estas pocas páginas, el ranking de páginas converge muy rápido. Así que volvamos a ejecutarlo. Correré diez y verás cómo converge esto. Así que ahí lo tienes. Converge. Y ahora, después de 12 iteraciones, veis que la diferencia entre el rango antiguo y el nuevo es porque es ese rango antiguo. Haré una iteración más para que puedas ver. Así que este rango anterior es inferior a 0,005. Así que ahora puedes ver que estos números se están estabilizando. Este es el promedio, ese número 005 es la diferencia promedio entre estas dos cosas. Ahora, si vamos a fingir ser Google por un momento. Podemos decir python3 spider.py. Así que hagamos diez páginas más. Ahora, lo que va a pasar aquí es que estas nuevas páginas tendrán una clasificación de 1, ¿de acuerdo? Así que salgamos. Así que si actualizo ahora y miro un nuevo rango. Así que están esos tipos que tienen un alto rango. Lo que veas, espero, está bien, para que veas nuevas páginas, ¿verdad? Estas son las nuevas que acabamos de recuperar. No sé si están enlazados o no y todos tienen uno, así que algunas páginas antiguas están 14 por encima. Algunas páginas, si vamos hacia abajo, están muy abajo, así que son páginas inútiles. Apuntan a algún sitio pero nadie las señala. Eso es lo que pasa con estos rankings de páginas, ¿vale? Lo que pasa es que los nuevos registros obtienen este 0,1. Entonces, si vuelvo a ejecutar el código de clasificación y ejecuto, ejecutemos cinco iteraciones. Verás que el delta promedio aumenta brevemente a medida que asimila estas nuevas páginas. Y luego vuelve a bajar. Y eso es lo que está pasando con Google. Es como hacer todo lo posible para obtener más páginas. Luego, se ejecuta el ranking de la página, que se altera un poco, pero luego vuelve a converger muy rápidamente. Y, por supuesto, tienen miles de millones de páginas y nosotros tenemos cientos de páginas , pero ya entiendes la idea. Vale, así puedo analizar el page rank 100 veces. Y después de un tiempo, apenas cambia. Así que eso es 2.7 elevado a la décima potencia negativa. Así que ahora permítanme ejecutarlo una vez más para actualizar las cosas. Y si actualizo esto, verás. Mira qué tan estables son estos números, 14,943591567, la diferencia está en el séptimo. Es por eso que todo este ranking de páginas es realmente genial. Parece que es muy caótico cuando empieza y ya está, ¿de acuerdo? Así que eso fue solo esto, Spank, ¿verdad? Splank and Spreset, podemos ver ese código y no me molestaré en ejecutarlo. Simplemente establece el old_rank en 1, eso es todo, es todo el código que tienes. Simplemente lo inicia y deja que se vuelva a ejecutar. Así que voy a parar ahora. Voy a empezar un nuevo vídeo en el que hablaré de esta fase, en la que vamos a visualizar los datos clasificados por página. [MÚSICA]